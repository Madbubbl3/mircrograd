{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start by building the Value object, to represent the individual components of a Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    \n",
    "    def __init__(self, data, inputs = (), op = \"\", label = \"\"):\n",
    "        self.data = data\n",
    "        self.predecesors = set(inputs)\n",
    "        self.op = op\n",
    "        self.grad = 0\n",
    "        self.label = label\n",
    "        self.backward = lambda: None\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return (f\"data of {self.label} = {self.data}; gradient = {self.grad}\")\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        # check if other is a data:\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        \n",
    "        # calculate the gradient for addition\n",
    "        def backward():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "        \n",
    "        # calculate the output of operation and assign it's local gradient \n",
    "        out =  Value(data = self.data + other.data, inputs=(self, other), op = \"+\")\n",
    "        out.backward = backward\n",
    "        \n",
    "        #return the value\n",
    "        return out\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return self + (-other)\n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        return self - other\n",
    "    \n",
    "    def __rmul__(self, other): # called on other * self, when self is not a number\n",
    "        return self * other\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        # check if other is a Value\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        \n",
    "        # calculate the _gradient for multiplication\n",
    "        def backward():\n",
    "            self.grad += out.grad * other.data\n",
    "            other.grad += out.grad * self.data\n",
    "        \n",
    "        # calculate the outpout of the operation and assign it it's respective backward function\n",
    "        out = Value(data = self.data * other.data, inputs=(self, other), op = \"*\")\n",
    "        out.backward = backward\n",
    "        \n",
    "        # return the output\n",
    "        return out\n",
    "    \n",
    "    def __truediv__(self, other): # self / other\n",
    "        return self * other**(-1)\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        return self * other**(-1)\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (float, int)) # this function only work with other\n",
    "        \n",
    "        out = Value(data = pow(self.data, other), inputs=(self,), op = \"**\")\n",
    "        \n",
    "        def backward():\n",
    "            self.grad += other * pow(self.data, other-1) * out.grad\n",
    "        \n",
    "        out.backward = backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def exp(self):\n",
    "        x = self.data\n",
    "        out = Value(data = math.exp(x),inputs=(self,), op=\"exp\")\n",
    "        def backward():\n",
    "            self.grad += out.data * out.grad\n",
    "        out.backward = backward\n",
    "        return out\n",
    "    \n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        e = math.exp(2*x)\n",
    "        out = Value(\n",
    "            data=((e-1)/(e+1)),\n",
    "            inputs=(self,),\n",
    "            op=\"tanh\",\n",
    "        )\n",
    "        \n",
    "        def backward():\n",
    "            self.grad += (1 - out.data**2) * out.grad\n",
    "    \n",
    "        out.backward = backward\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backPropagation(self):\n",
    "        '''\n",
    "        Start the backpropagation from this node\n",
    "        '''\n",
    "        \n",
    "        # set the gradient of this node to 1\n",
    "        self.grad = 1\n",
    "        \n",
    "        # build a helper function to create the topological sorting of the graph\n",
    "        def topologicalSorting(node):\n",
    "            # create local variable\n",
    "            L = []\n",
    "            s = set()\n",
    "            \n",
    "            # recursive sorting\n",
    "            def topo(node:Value):\n",
    "                if node not in s:\n",
    "                    s.add(node)\n",
    "                    for parent in node.predecesors:\n",
    "                        topo(parent)\n",
    "                    L.append(node)\n",
    "            topo(node)\n",
    "            return L\n",
    "        \n",
    "        # call the backward method on each node, starting from the last one\n",
    "        for node in topologicalSorting(self)[::-1]:\n",
    "            node.backward()\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can create the neuron class to build neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \n",
    "    def __init__(self, nin):\n",
    "        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n",
    "        self.b = Value(random.uniform(-1,1))\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        activation = sum((wi*xi for wi, xi in zip(self.w, x)),self.b).tanh()\n",
    "        return activation\n",
    "    \n",
    "class Layer:\n",
    "    \n",
    "    def __init__(self, nin, nout):\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        activation = [n(x) for n in self.neurons]\n",
    "        return activation\n",
    "    \n",
    "class MLP:\n",
    "    \n",
    "    def buildLayers(nin, nouts):\n",
    "        layers = [Layer(nin, nouts[0])]\n",
    "        for n in range(1,len(nouts)):\n",
    "            layers.append(Layer(nouts[n-1], nouts[n]))\n",
    "        return layers\n",
    "    \n",
    "    def __init__(self, nin, nouts:list):\n",
    "        self.io = [nin] + nouts\n",
    "        self.layers = [Layer(self.io[n], self.io[n+1]) for n in range(len(nouts))]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        activation = [layer(x) for layer in self.layers]\n",
    "        return activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[data of  = 0.8969144768112074; gradient = 0,\n",
       "  data of  = 0.005159696092638309; gradient = 0,\n",
       "  data of  = 0.4672414160402595; gradient = 0,\n",
       "  data of  = 0.9823025046346043; gradient = 0],\n",
       " [data of  = -0.9978851657256539; gradient = 0,\n",
       "  data of  = 0.9992265756136209; gradient = 0,\n",
       "  data of  = -0.9929183651806309; gradient = 0,\n",
       "  data of  = -0.9239658678427609; gradient = 0]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test activation for a neuron\n",
    "neuron = Neuron(3)\n",
    "neuron((1,2,3))\n",
    "\n",
    "# test activation for a layer\n",
    "layer = Layer(3,4)\n",
    "layer((1,2,3))\n",
    "\n",
    "# test activation for a neural network\n",
    "nn = MLP(3,[4,4])\n",
    "nn((1,2,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba312b34e25661c03676c07f1dceb303d7496d4d0ee3226111a97549ba3b54c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
